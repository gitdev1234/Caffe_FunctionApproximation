"# test_iter specifies how many forward passes the test should carry out."
"# In the case we have a test batch size 40 and 100 test iterations,"
"# covering the full 400 test iterations"
"test_iter: 100"
""
"# Carry out testing every 20 training iterations."
"test_interval: 20"
""
"# The base learning rate, momentum and the weight decay of the network."
"base_lr: 0.01"
"momentum: 0.9"
"weight_decay: 0.0005"
""
"# The learning rate policy"
"lr_policy: 'inv'"
"gamma: 0.0001"
"power: 0.75"
""
"# Display every 20 iterations"
"display: 20"
""
"# The maximum number of iterations"
"max_iter: 10000"
""
"# snapshot intermediate results"
"snapshot: 5000"
"snapshot_prefix: 'input__innerproduct_tanh_innerproduct_tanh_output_loss_solver'"
""
"# solver mode: CPU or GPU"
"solver_mode: CPU"
""
"# The train/test net protocol buffer definition"
"net_param { "
"	name: 'CaffeNet'"
"	layer {"
"	  name: 'data'"
"	  type: 'Input'"
"	  top: 'data'"
"	  top: 'label'"
"	  input_param { shape: { dim: 1 dim: 1 dim: 1 dim: 1 } }"
"	}"
"	layer {"
"	  name: 'inputLayer'"
"	  type: 'InnerProduct'"
"	  bottom: 'data'"
"	  top: 'inputLayer'"
"	  inner_product_param {"
"	    num_output: 10"
"	    weight_filler {"
"	      type: 'xavier'"
"	    }"
"	    bias_filler {"
"	      type: 'constant'"
"	    }"
"	  }"
"	}"
"	layer {"
"	  name: 'activatedInputLayer'"
"	  type: 'TanH'"
"	  bottom: 'inputLayer'"
"	  top: 'activatedInputLayer'"
"	}"
"	layer {"
"	  name: 'outputLayer'"
"	  type: 'InnerProduct'"
"	  bottom: 'activatedInputLayer'"
"	  top: 'outputLayer'"
"	  inner_product_param {"
"	    num_output: 1"
"	    weight_filler {"
"	      type: 'xavier'"
"	    }"
"	    bias_filler {"
"	      type: 'constant'"
"	    }"
"	  }"
"	}"
"	layer {"
"	  name: 'activatedOutputLayer'"
"	  type: 'TanH'"
"	  bottom: 'outputLayer'"
"	  top: 'activatedOutputLayer'"
"	}"
"	layer {"
"	  name: 'loss'"
"	  type: 'EuclideanLoss'"
"	  bottom: 'activatedOutputLayer'"
"	  bottom: 'label'"
"	  top: 'loss'"
"	}"
""
"}"

